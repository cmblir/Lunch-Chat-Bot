{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import chromedriver_autoinstaller\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_list = ['마포구','서대문구','은평구','종로구','중구','용산구','성동구','광진구',\n",
    "           '동대문구','성북구','강북구','도봉구','노원구','중랑구','강동구','송파구',\n",
    "           '강남구','서초구','관악구','동작구','영등포구','금천구','구로구','양천구','강서구']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for index, gu_name in tqdm(enumerate(gu_list)):\n",
    "    cnt += 1\n",
    "    fileName = f'{gu_name}_{cnt}.csv' # index.__str__() + '_' + gu_name + '.'+'csv'\n",
    "    file = open(fileName, 'w', encoding='utf-8')\n",
    "    file.write(\"카페명\" + \"|\" + \"주소\" + \"|\" + \"영업시간\" + \"|\" + \"전화번호\" + \"|\" + \"대표사진주소\" + \"\\n\")\n",
    "    file.close()                                    # 처음에 csv파일에 칼럼명 만들어주기\n",
    "    # 크롬 버젼 확인 후 새로운 드라이버 설치해서 실행\n",
    "    chrome_ver = chromedriver_autoinstaller.get_chrome_version().split('.')[0]  #크롬드라이버 버전 확인\n",
    "\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\") # 시크릿 모드\n",
    "    chrome_options.add_argument(\"--headless\") # 리눅스 GUI 없는 디스플레이 모드\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # 리소스에 대한 엑서스 방지\n",
    "    chrome_options.add_argument(\"--disable-setuid-sandbox\") # 크롬 충돌 방지\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\") # 메모리 부족 에러 방지\n",
    "    chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "    try: # 크롬 드라이버\n",
    "        driver = webdriver.Chrome(f'./{chrome_ver}/chromedriver', chrome_options=chrome_options)   \n",
    "    except:\n",
    "        chromedriver_autoinstaller.install(True)\n",
    "        driver = webdriver.Chrome(f'./{chrome_ver}/chromedriver', chrome_options=chrome_options)\n",
    "\n",
    "    # WebDruverException Error 방지 기존의 드라이버 버젼으로 지정\n",
    "    # driver = webdriver.Chrome(executable_path='/Users/cmblir/Python/Musinsa-Analysis/100/chromedriver')\n",
    "    driver.implicitly_wait(10) # 10초정도 멈추기\n",
    "    \n",
    "    driver.get('https://map.kakao.com/')  # 주소 가져오기\n",
    "    search_area = driver.find_element(By.XPATH, '//*[@id=\"search.keyword.query\"]') # 검색 창\n",
    "    search_area.send_keys(gu_name + ' 카페')  # 검색어 입력\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
    "    driver.implicitly_wait(3) # 기다려 주자\n",
    "    more_page = driver.find_element(By.ID, \"info.search.place.more\")\n",
    "    # more_page.click()\n",
    "    more_page.send_keys(Keys.ENTER) # 더보기 누르고\n",
    "    # 첫 번째 검색 페이지 끝\n",
    "    # driver.implicitly_wait(5) # 기다려 주자\n",
    "    time.sleep(1)\n",
    "\n",
    "    # next 사용 가능?\n",
    "    next_btn = driver.find_element(By.ID, \"info.search.page.next\")\n",
    "    has_next = \"disabled\" not in next_btn.get_attribute(\"class\").split(\" \")\n",
    "    Page = 1\n",
    "    while has_next: # 다음 페이지가 있으면 loop\n",
    "    # for i in range(2, 6): # 2, 3, 4, 5\n",
    "        file = open(fileName, 'a', encoding='utf-8')\n",
    "        time.sleep(1)\n",
    "        # place_lists = driver.find_element(By.CSS_SELECTOR, ('#info\\.search\\.place\\.list > li:nth-child(1)')\n",
    "        # 페이지 루프\n",
    "        #info\\.search\\.page\\.no1 ~ .no5\n",
    "        page_links = driver.find_elements(By.CSS_SELECTOR, \"#info\\.search\\.page a\")\n",
    "        pages = [link for link in page_links if \"HIDDEN\" not in link.get_attribute(\"class\").split(\" \")]\n",
    "        # print(len(pages), \"개의 페이지 있음\")\n",
    "        # pages를 하나씩 클릭하면서\n",
    "        for i in range(1, 6):\n",
    "            xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "            try:\n",
    "                page = driver.find_element(By.XPATH, xPath)\n",
    "                page.send_keys(Keys.ENTER)\n",
    "            except ElementNotInteractableException:\n",
    "                print('End of Page')\n",
    "                break;\n",
    "            sleep(3)\n",
    "            place_lists = driver.find_elements(By.CSS_SELECTOR, '#info\\.search\\.place\\.list > li')\n",
    "            for p in place_lists: # WebElement\n",
    "                # print(p.get_attribute('innerHTML'))\n",
    "                # print(\"type of p:\", type(p))\n",
    "                store_html = p.get_attribute('innerHTML')\n",
    "                store_info = BeautifulSoup(store_html, \"html.parser\")\n",
    "                # BS -> 분석\n",
    "                #\n",
    "                place_name = store_info.select('.head_item > .tit_name > .link_name')\n",
    "                # place_address = store_info.select('.info_item > .addr > p')\n",
    "                # place_hour = store_info.select('.info_item > .openhour > p > a')\n",
    "                # place_tel = store_info.select('.info_item > .contact > span')\n",
    "                 # print(\"length:\", len(place_name))\n",
    "                if len(place_name) == 0:\n",
    "                    continue # 광고\n",
    "                place_name = store_info.select('.head_item > .tit_name > .link_name')[0].text\n",
    "                place_address = store_info.select('.info_item > .addr > p')[0].text\n",
    "                place_hour = store_info.select('.info_item > .openhour > p > a')[0].text\n",
    "                place_tel = store_info.select('.info_item > .contact > span')[0].text\n",
    "\n",
    "\n",
    "                # 사진url 수집\n",
    "                detail = p.find_element(By.CSS_SELECTOR, 'div.info_item > div.contact > a.moreview')\n",
    "                detail.send_keys(Keys.ENTER)\n",
    "\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "                place_photo = \"\"\n",
    "                try:\n",
    "                    photo = driver.find_elements(By.CSS_SELECTOR, 'span.bg_present')\n",
    "                    photo_url = photo.get_attribute('style')\n",
    "                    m = re.search('\"(.+?)\"', photo_url)\n",
    "                    if m:\n",
    "                        place_photo = m.group(1)\n",
    "                    else:\n",
    "                        place_photo = \"\"\n",
    "                except:\n",
    "                    place_photo = \"\"\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                print(place_name, place_photo)\n",
    "\n",
    "                file.write(place_name + \"|\" + place_address + \"|\" + place_hour + \"|\" + place_tel + \"|\" + place_photo + \"\\n\")\n",
    "            print(i, ' of', ' [ ' , Page, ' ] ')\n",
    "        next_btn = driver.find_element(By.ID, \"info.search.page.next\")\n",
    "        has_next = \"disabled\" not in next_btn.get_attribute(\"class\").split(\" \")\n",
    "        if not has_next:\n",
    "            print('Arrow is Disabled')\n",
    "            driver.close()\n",
    "            file.close()\n",
    "            break # 다음 페이지 없으니까 종료\n",
    "        else: # 다음 페이지 있으면\n",
    "            Page += 1\n",
    "            next_btn.send_keys(Keys.ENTER)\n",
    "    print(\"End of Crawl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어반플랜트 합정 \n",
      "피오니 홍대점 \n",
      "바다회사랑 \n",
      "프릳츠 도화점 \n",
      "소이연남 \n",
      "을밀대 본점 \n",
      "크레이지카츠 \n",
      "바다회사랑 2호점 \n",
      "테이스티버거 \n",
      "어글리베이커리 \n",
      "황금콩밭 \n",
      "망원동즉석우동전문돈까스 본점 \n",
      "역전회관 \n",
      "오레노라멘 합정본점 \n",
      "마포진짜원조최대포 본점 \n",
      "1  of  [  1  ] \n",
      "진미식당 \n",
      "몽중헌 공덕점 \n",
      "미쁘동 \n",
      "마포나루 도화본점 \n",
      "감성타코 홍대점 \n",
      "하이디라오 홍대지점 \n",
      "평이담백뼈칼국수 \n",
      "원조조박집 본관 \n",
      "헤키 \n",
      "스케줄 합정 \n",
      "943킹스크로스 \n",
      "마포양지설렁탕 \n",
      "곱 마포점 \n",
      "카페공명 \n",
      "연교 \n",
      "2  of  [  1  ] \n",
      "진짜파스타 \n",
      "오츠커피 마포점 \n",
      "모연 \n",
      "카페 레이어드 연남점 \n",
      "우리바다수산 \n",
      "우동카덴 \n",
      "연남토마 본점 \n",
      "소금집델리 망원 \n",
      "아소정 \n",
      "리치몬드과자점 성산본점 \n",
      "중화복춘 \n",
      "비파티세리 공덕점 \n",
      "마포옥 \n",
      "진진 본관 \n",
      "우와 홍대본점 \n",
      "3  of  [  1  ] \n",
      "두껍삼 마포직영점 \n",
      "앤트러사이트 합정점 \n",
      "청어람 망원점 \n",
      "포비 합정점 \n",
      "맛이차이나 \n",
      "각시보쌈 \n",
      "진대감 마포점 \n",
      "또보겠지떡볶이집 호호시스터점 \n",
      "마포원조떡볶이 \n",
      "앤트러사이트 서교점 \n",
      "카와카츠 \n",
      "정돈 \n",
      "툭툭누들타이 \n",
      "테일러커피 서교점 \n",
      "조선시대 \n",
      "4  of  [  1  ] \n",
      "한강껍데기 \n",
      "감나무집기사식당 \n",
      "산울림1992 \n",
      "당인리책발전소 \n",
      "최강금돈까스 \n",
      "무신사테라스 \n",
      "코코로카라 \n",
      "옥동식 서교점 \n",
      "색동저고리 마포점 \n",
      "마녀주방 홍대점 \n",
      "일일향 마포점 \n",
      "경기떡집 \n",
      "뉴오더클럽 \n",
      "어메이징농카이 \n",
      "합정고깃집 \n",
      "5  of  [  1  ] \n",
      "일등식당 \n",
      "황곱 홍대점 \n",
      "커피리브레 연남점 \n",
      "몰토베네 \n",
      "굴다리식당 \n",
      "카쿠시타 \n",
      "와이키키마켓 \n",
      "톤앤매너 \n",
      "다이닝원 상암점 \n",
      "칸다소바 홍대점 \n",
      "개화기요정 \n",
      "1984 \n",
      "피자네버슬립스 합정본점 \n",
      "땡스오트 연남점 \n",
      "램랜드 \n",
      "1  of  [  2  ] \n",
      "아오이토리 \n",
      "이치류 홍대본점 \n",
      "가미우동 \n",
      "카미야 \n",
      "중화복춘 골드동교점 \n",
      "빈브라더스 합정점 \n",
      "스파카나폴리 \n",
      "오랑지 \n",
      "콜린 \n",
      "부산집 \n",
      "냉장고 \n",
      "합정광안리 \n",
      "장수갈매기 본점 \n",
      "락희옥 마포본점 \n",
      "합정옥 \n",
      "2  of  [  2  ] \n",
      "여우골 홍대점 \n",
      "이치젠 \n",
      "또보겠지떡볶이집 깐따삐아점 \n",
      "마루심 마포점 \n",
      "또보겠지떡볶이집 붕붕허니비점 \n",
      "지로우라멘 \n",
      "프리모바치오바치 홍대본점 \n",
      "교다이야 \n",
      "대도식당 마포대로점 \n",
      "마포곱창타운 \n",
      "비스트로사랑방 \n",
      "강강술래 홍대점 \n",
      "덕승재 상암동본점 \n",
      "미미램양꼬치 \n",
      "철길왕갈비살 \n",
      "3  of  [  2  ] \n",
      "소점 \n",
      "부산갈매기 \n",
      "21세기 우리바다수산 \n",
      "멕시코식당 \n",
      "연어롭다 \n",
      "하하 \n",
      "디벙크 \n",
      "행진 \n",
      "수라간 \n",
      "비스트로주라 \n",
      "오마 \n",
      "담택 \n",
      "복성각 마포본점 \n",
      "카페나하 \n",
      "일미락 상암점 \n",
      "4  of  [  2  ] \n",
      "얼스어스 \n",
      "땡스네이쳐 \n",
      "이요이요스시 공덕1호점 \n",
      "장작집 연남본점 \n",
      "커피가게동경 \n",
      "샌드커피 논탄토 \n",
      "산더미불고기 \n",
      "키쉬미뇽 \n",
      "조선초가한끼 \n",
      "멘야산다이메 홍대점 \n",
      "히츠지야4.5 \n",
      "부영각 \n",
      "코끼리즉석떡볶이 \n",
      "연남제비 \n",
      "투떰즈업 \n",
      "5  of  [  2  ] \n",
      "공감 홍대2호점 \n",
      "테일러커피 연남1호점 \n",
      "더담 \n",
      "경주식당 \n",
      "육시리 마포직영점 \n",
      "소바식당 망원점 \n",
      "슬로우캘리 연남본점 \n",
      "아이엠베이글 공덕점 \n",
      "브런치가 \n",
      "갓잇 연남점 \n",
      "곱창파는고깃집 \n",
      "미스터리브루잉컴퍼니 \n",
      "작당모의 \n",
      "쿠시노주방 \n",
      "월화고기 상암직영 1호점 \n",
      "1  of  [  3  ] \n",
      "딥블루레이크 \n",
      "명인갈비 \n",
      "마시타야 \n",
      "또보겠지떡볶이집 스마일보이점 \n",
      "이미커피 \n",
      "감성타코&그릴 합정점 \n",
      "버터밀크 \n",
      "고향집 \n",
      "파네트 \n",
      "우이락 망원본점 \n",
      "원마산아구찜 본관 \n",
      "이츠모라멘 \n",
      "라멘트럭 상수본점 \n",
      "시루케이크 \n",
      "히츠지야 한국본점 \n",
      "2  of  [  3  ] \n",
      "구공탄곱창 본점 \n",
      "또보겠지떡볶이집 호호피크닉점 \n",
      "부탄츄 홍대점 \n",
      "제주정원 \n",
      "교대이층집 상암점 \n",
      "양화정숯불갈비 \n",
      "서강8경 \n",
      "이춘복참치 공덕점 \n",
      "영동감자탕 \n",
      "SOUPER 마포 \n",
      "시오 \n",
      "송가네감자탕 \n",
      "육장 \n",
      "월강부산돼지국밥 \n",
      "콩카페 연남점 \n",
      "3  of  [  3  ] \n",
      "마포왕족발 \n",
      "삿뽀로 홍대점 \n",
      "아우룸 \n",
      "사루카메 \n",
      "빌리프커피로스터스 \n",
      "봉피양 마포점 \n",
      "야키토리묵 \n",
      "역전포장마차 \n",
      "W카페 \n",
      "잇텐고 \n",
      "팔로피자 \n",
      "피오니 연남점 \n",
      "더피자보이즈 홍대입구역점 \n",
      "홍스쭈꾸미 홍대본점 \n",
      "경양카츠 연남점 \n",
      "4  of  [  3  ] \n",
      "김덕후의곱창조 홍대본점 \n",
      "요코쵸 \n",
      "더피자보이즈 \n",
      "빠넬로 \n",
      "무대륙 \n",
      "꿀돼지집 \n",
      "신촌서서갈비 \n",
      "하하&김종국의 401정육식당 홍대본점 \n",
      "하카타분코 \n",
      "비트포비아 홍대던전점 \n",
      "82년생김민경X카페르세 \n",
      "더페이머스버거 홍대점 \n",
      "괴르츠 \n",
      "허밍벨라 \n",
      "락희돈 \n",
      "5  of  [  3  ] \n",
      "조선화로구이 \n",
      "너랑나랑호프 망원점 \n",
      "순대일번지 \n",
      "왔쏘 홍대점 \n",
      "손오공마라탕 \n",
      "모아새 \n",
      "만복기사식당 \n",
      "크래버대게나라 마포점 \n",
      "딩가케이크 \n",
      "나랑가 \n",
      "발리문 \n",
      "공감 합정점 \n",
      "원조양평신내서울해장국 마포직영점 \n",
      "베르데 \n",
      "탑클라우드23 \n",
      "1  of  [  4  ] \n",
      "정정 공덕1호점 \n",
      "제비다방 \n",
      "남해바다 \n",
      "카페스콘 \n",
      "더페이머스램 \n",
      "서울안심축산정육식당 마포직영점 \n",
      "연남취향 \n",
      "포가레 \n",
      "소코아 홍대점 \n",
      "카레시 \n",
      "옥소반 상암점 \n",
      "오리지널시카고피자 홍대본점 \n",
      "혼가츠 \n",
      "프롬하노이 \n",
      "옥자회관 \n",
      "2  of  [  4  ] \n",
      "홍대조폭떡볶이 \n",
      "포멜로빈 공덕점 \n",
      "씨스루 홍대연남점 \n",
      "밤부베이커리&브루잉 \n",
      "카밀로라자네리아 \n",
      "진진가연 \n",
      "연남방앗간 \n",
      "터틀힙 \n",
      "강화통통생고기 본점 \n",
      "김영섭초밥 \n",
      "파델라 \n",
      "히어로보드게임카페 홍대1호점 \n",
      "김앤김대게 서교점 \n",
      "향미 \n",
      "더다이닝랩 \n",
      "3  of  [  4  ] \n",
      "주막 \n",
      "풍천장어 연남점 \n",
      "비스트로큐슈 \n",
      "로운 신촌점 \n",
      "카페 클로이인패리스 \n",
      "식신매운갈비찜 \n",
      "그레이랩 \n",
      "카페 지금여기 \n",
      "연어촌 \n",
      "멘야하나비 합정점 \n",
      "앤디스커피 \n",
      "성미골고기마을 \n",
      "도시의어부 상암동DMC점 \n",
      "광야 \n",
      "이빠네마그릴 홍대점 \n",
      "4  of  [  4  ] \n",
      "연주방 \n",
      "공상온도 \n",
      "카페장쌤 \n",
      "고쿠텐 홍대점 \n",
      "멘야준 \n",
      "백년토종삼계탕 본점 \n",
      "그로토 \n",
      "스시엔준 \n",
      "서울이스케이프룸 홍대2호점 \n",
      "올드상해 \n",
      "카시 \n",
      "돈주는남자 본점 \n",
      "무한리필808 \n",
      "함루 \n",
      "노티드 연남 \n",
      "5  of  [  4  ] \n",
      "브루라티오 홍대점 \n",
      "영광보쌈 \n",
      "로쏘1924 \n",
      "라그릴리아 공덕점 \n",
      "한상가득왕솥뚜껑 \n",
      "마포나루 아크로점 \n",
      "밀라노식당 \n",
      "대포막창 \n",
      "카에루 \n",
      "스아게K \n",
      "교대이층집 마포점 \n",
      "라헬의부엌 홍대점 \n",
      "만만코코로 홍대점 \n",
      "능라도 마포점 \n",
      "오목집 마포점 \n",
      "1  of  [  5  ] \n",
      "당가원 \n",
      "고기꾼김춘배 \n",
      "마포원조주물럭 \n",
      "크라이치즈버거 상암점 \n",
      "라오삐약 \n",
      "비로소커피 \n",
      "베어스덴베이커리 \n",
      "녹기전에 \n",
      "초월양곱창 \n",
      "마포갈매기 \n",
      "본점최대포 1호점 \n",
      "아웃닭 홍대점 \n",
      "장끼전 \n",
      "랑데자뷰 상수점 \n",
      "대관령메밀막국수자연샤브샤브 \n",
      "2  of  [  5  ] \n",
      "서대문양꼬치 \n",
      "철인7호치킨 홍대점 \n",
      "멘지 \n",
      "지하102호 3호점 \n",
      "여우골 홍대서교점 \n",
      "신촌즉석생우동 \n",
      "훠궈나라 홍대점 \n",
      "루나씨엘로 \n",
      "서룡 \n",
      "홍익게장 홍대본점 \n",
      "예티 \n",
      "델리인디아 \n",
      "고구려 홍대점 \n",
      "뚜띠쿠치나 공덕점 \n",
      "광합성카페 \n",
      "3  of  [  5  ] \n",
      "은행골 홍대점 \n",
      "망원시장손칼국수 \n",
      "짬뽕지존 홍대직영점 \n",
      "ESC방탈출카페 홍대점 \n",
      "코노미 홍대점 \n",
      "민트하임 \n",
      "청년화로1987 \n",
      "온미동 연남점 \n",
      "몽미 \n",
      "커피폴리 \n",
      "당도 \n",
      "연남동질리 \n",
      "바코포차 \n",
      "현래장 \n",
      "규자카야모토 \n",
      "4  of  [  5  ] \n",
      "산왕반점 연남동본점 \n",
      "스탠스커피 \n",
      "도쿄빙수 본점 \n",
      "후라토식당 상수직영점 \n",
      "마포우사미 \n",
      "온블랙94 \n",
      "서산꽃게 \n",
      "네시사분 \n",
      "배떼기곱창 홍대점 \n",
      "난 \n",
      "멜로우 \n",
      "타오마라탕 합정 \n",
      "초마 홍대본점 \n",
      "히게쯔라 \n",
      "미스터리룸이스케이프 홍대2호점 \n",
      "5  of  [  5  ] \n",
      "동차밥 \n",
      "퍼셉션 (Perception) \n",
      "8810리스트레토바 \n",
      "와인로그 \n",
      "마이클돈까스 상암본점 \n",
      "의정부부대찌개 \n",
      "산리오러버스클럽 \n",
      "38도씨식당 \n",
      "랜디스도넛 연남점 \n",
      "마이클 \n",
      "마포청학동부침개 \n",
      "크래프트한스 연남직영점 \n",
      "달콤한거짓말 \n",
      "제임스시카고피자 홍대본점 \n",
      "외백 \n",
      "1  of  [  6  ] \n",
      "스시소라 마포점 \n",
      "사람사는 고깃집 김일도 마포공덕점 \n",
      "불이아 본점 \n",
      "빵나무 \n",
      "윤씨밀방 \n",
      "쿠시파파 \n",
      "만두란 \n",
      "보승회관 홍대직영점 \n",
      "인기명 마포점 \n",
      "라무라 \n",
      "몽중식 \n",
      "몽마르뜨언덕위 은하수다방 \n",
      "연남주막1987 \n",
      "오스테리아샘킴 \n",
      "쭌곱창 \n",
      "2  of  [  6  ] \n",
      "블루쿠치나 \n",
      "심양 홍대점 \n",
      "홍대인파스타 \n",
      "돈화 합정본점 \n",
      "홍대조폭떡볶이 홍대2호점 \n",
      "카페여유 \n",
      "이리카페 \n",
      "펠른 \n",
      "유메 \n",
      "쿠루미 \n",
      "기요한 \n",
      "히어로보드게임카페 홍대2호점 \n",
      "앵춘 \n",
      "원조마포껍데기집 \n",
      "꼬르소산도 \n",
      "3  of  [  6  ] \n",
      "파스타공작소 \n",
      "문데이 \n",
      "낙곱새미장원 \n",
      "카페105 \n",
      "저스티나 \n",
      "르쁘띠푸 홍대본점 \n",
      "합정동 원조황소곱창구이전문 \n",
      "홍대개미 홍대점 \n",
      "딥커피 \n",
      "구공탄곱창 합정2호점 \n",
      "가원 \n",
      "푸하하크림빵 \n",
      "쿠이신보 \n",
      "모파상 \n",
      "오늘그대와 \n",
      "4  of  [  6  ] \n",
      "커피냅로스터스 연남동 \n",
      "카페 사운드웨이브 \n",
      "미담진족 \n",
      "교동집 \n",
      "홍익닭 한마리 홍대본점 \n",
      "꼼보포차 홍대2호점 \n",
      "어리 \n",
      "티크닉 \n",
      "희희 \n",
      "수저가 \n",
      "그동네떡볶이 홍대점 \n",
      "심플리타이 합정점 \n",
      "어니스트팬케이크 \n",
      "다옴383 \n",
      "치킨앤카레군 \n",
      "5  of  [  6  ] \n",
      "스시노백쉐프 홍대연남점 \n",
      "마포소문난원조족발 \n",
      "츠케루 \n",
      "키움참치 홍대점 \n",
      "와우끝집 \n",
      "연희중식 \n",
      "애프터눈커피 \n",
      "카페로제 \n",
      "발리인망원 \n",
      "신김치생삼겹살 \n",
      "자세 \n",
      "반미프엉 \n",
      "재미난조각가 홍대점 \n",
      "서울큰입탕 \n",
      "하카타나카 \n",
      "1  of  [  7  ] \n",
      "루프탑어반비치 \n",
      "삼거리포차 \n",
      "빕스 합정역점 \n",
      "딩굴딩굴알타미라 \n",
      "미어캣프랜즈 \n",
      "삼곱식당 합정점 \n",
      "아웃백스테이크하우스 합정점 \n",
      "정광수의돈까스가게 \n",
      "온돌 \n",
      "군산찜 \n",
      "고베규카츠 상수점 \n",
      "고수포차 \n",
      "17도씨 \n",
      "바스버거 상암DMC점 \n",
      "미완성식탁 \n",
      "2  of  [  7  ] \n",
      "엘비스텍 \n",
      "어른이대공원 \n",
      "히말라야어죽 \n",
      "간코 \n",
      "웃사브 \n",
      "비포블루밍 \n",
      "금옥당 서교점 \n",
      "이공족발 홍대직영점 \n",
      "망원그곳 \n",
      "신라스테이 마포 카페 \n",
      "다다랩 \n",
      "이대조뼈다귀 \n",
      "홍마떡 홍대본점 \n",
      "마포오향족발 \n",
      "계고기집 \n",
      "3  of  [  7  ] \n"
     ]
    }
   ],
   "source": [
    "cnt = 100\n",
    "for index, gu_name in tqdm(enumerate(gu_list)):\n",
    "    cnt += 1\n",
    "    fileName = f'{gu_name}_{cnt}.csv' # index.__str__() + '_' + gu_name + '.'+'csv'\n",
    "    file = open(fileName, 'w', encoding='utf-8')\n",
    "    file.write(\"맛집명\" + \"|\" + \"주소\" + \"|\" + \"영업시간\" + \"|\" + \"전화번호\" + \"|\" + \"대표사진주소\" + \"\\n\")\n",
    "    file.close()                                    # 처음에 csv파일에 칼럼명 만들어주기\n",
    "    # 크롬 버젼 확인 후 새로운 드라이버 설치해서 실행\n",
    "    chrome_ver = chromedriver_autoinstaller.get_chrome_version().split('.')[0]  #크롬드라이버 버전 확인\n",
    "\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\") # 시크릿 모드\n",
    "    chrome_options.add_argument(\"--headless\") # 리눅스 GUI 없는 디스플레이 모드\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # 리소스에 대한 엑서스 방지\n",
    "    chrome_options.add_argument(\"--disable-setuid-sandbox\") # 크롬 충돌 방지\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\") # 메모리 부족 에러 방지\n",
    "    chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "    try: # 크롬 드라이버\n",
    "        driver = webdriver.Chrome(f'./{chrome_ver}/chromedriver', chrome_options=chrome_options)   \n",
    "    except:\n",
    "        chromedriver_autoinstaller.install(True)\n",
    "        driver = webdriver.Chrome(f'./{chrome_ver}/chromedriver', chrome_options=chrome_options)\n",
    "\n",
    "    # WebDruverException Error 방지 기존의 드라이버 버젼으로 지정\n",
    "    # driver = webdriver.Chrome(executable_path='/Users/cmblir/Python/Musinsa-Analysis/100/chromedriver')\n",
    "    driver.implicitly_wait(10) # 10초정도 멈추기\n",
    "    \n",
    "    driver.get('https://map.kakao.com/')  # 주소 가져오기\n",
    "    search_area = driver.find_element(By.XPATH, '//*[@id=\"search.keyword.query\"]') # 검색 창\n",
    "    search_area.send_keys(gu_name + ' 맛집')  # 검색어 입력\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
    "    driver.implicitly_wait(3) # 기다려 주자\n",
    "    more_page = driver.find_element(By.ID, \"info.search.place.more\")\n",
    "    # more_page.click()\n",
    "    more_page.send_keys(Keys.ENTER) # 더보기 누르고\n",
    "    # 첫 번째 검색 페이지 끝\n",
    "    # driver.implicitly_wait(5) # 기다려 주자\n",
    "    time.sleep(1)\n",
    "\n",
    "    # next 사용 가능?\n",
    "    next_btn = driver.find_element(By.ID, \"info.search.page.next\")\n",
    "    has_next = \"disabled\" not in next_btn.get_attribute(\"class\").split(\" \")\n",
    "    Page = 1\n",
    "    while has_next: # 다음 페이지가 있으면 loop\n",
    "    # for i in range(2, 6): # 2, 3, 4, 5\n",
    "        file = open(fileName, 'a', encoding='utf-8')\n",
    "        time.sleep(1)\n",
    "        # place_lists = driver.find_element(By.CSS_SELECTOR, ('#info\\.search\\.place\\.list > li:nth-child(1)')\n",
    "        # 페이지 루프\n",
    "        #info\\.search\\.page\\.no1 ~ .no5\n",
    "        page_links = driver.find_elements(By.CSS_SELECTOR, \"#info\\.search\\.page a\")\n",
    "        pages = [link for link in page_links if \"HIDDEN\" not in link.get_attribute(\"class\").split(\" \")]\n",
    "        # print(len(pages), \"개의 페이지 있음\")\n",
    "        # pages를 하나씩 클릭하면서\n",
    "        for i in range(1, 6):\n",
    "            xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "            try:\n",
    "                page = driver.find_element(By.XPATH, xPath)\n",
    "                page.send_keys(Keys.ENTER)\n",
    "            except ElementNotInteractableException:\n",
    "                print('End of Page')\n",
    "                break;\n",
    "            sleep(3)\n",
    "            place_lists = driver.find_elements(By.CSS_SELECTOR, '#info\\.search\\.place\\.list > li')\n",
    "            for p in place_lists: # WebElement\n",
    "                # print(p.get_attribute('innerHTML'))\n",
    "                # print(\"type of p:\", type(p))\n",
    "                store_html = p.get_attribute('innerHTML')\n",
    "                store_info = BeautifulSoup(store_html, \"html.parser\")\n",
    "                # BS -> 분석\n",
    "                #\n",
    "                place_name = store_info.select('.head_item > .tit_name > .link_name')\n",
    "                # place_address = store_info.select('.info_item > .addr > p')\n",
    "                # place_hour = store_info.select('.info_item > .openhour > p > a')\n",
    "                # place_tel = store_info.select('.info_item > .contact > span')\n",
    "                 # print(\"length:\", len(place_name))\n",
    "                if len(place_name) == 0:\n",
    "                    continue # 광고\n",
    "                place_name = store_info.select('.head_item > .tit_name > .link_name')[0].text\n",
    "                place_address = store_info.select('.info_item > .addr > p')[0].text\n",
    "                place_hour = store_info.select('.info_item > .openhour > p > a')[0].text\n",
    "                place_tel = store_info.select('.info_item > .contact > span')[0].text\n",
    "\n",
    "\n",
    "                # 사진url 수집\n",
    "                detail = p.find_element(By.CSS_SELECTOR, 'div.info_item > div.contact > a.moreview')\n",
    "                detail.send_keys(Keys.ENTER)\n",
    "\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "                place_photo = \"\"\n",
    "                try:\n",
    "                    photo = driver.find_elements(By.CSS_SELECTOR, 'span.bg_present')\n",
    "                    photo_url = photo.get_attribute('style')\n",
    "                    m = re.search('\"(.+?)\"', photo_url)\n",
    "                    if m:\n",
    "                        place_photo = m.group(1)\n",
    "                    else:\n",
    "                        place_photo = \"\"\n",
    "                except:\n",
    "                    place_photo = \"\"\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                print(place_name, place_photo)\n",
    "\n",
    "                file.write(place_name + \"|\" + place_address + \"|\" + place_hour + \"|\" + place_tel + \"|\" + place_photo + \"\\n\")\n",
    "            print(i, ' of', ' [ ' , Page, ' ] ')\n",
    "        next_btn = driver.find_element(By.ID, \"info.search.page.next\")\n",
    "        has_next = \"disabled\" not in next_btn.get_attribute(\"class\").split(\" \")\n",
    "        if not has_next:\n",
    "            print('Arrow is Disabled')\n",
    "            driver.close()\n",
    "            file.close()\n",
    "            break # 다음 페이지 없으니까 종료\n",
    "        else: # 다음 페이지 있으면\n",
    "            Page += 1\n",
    "            next_btn.send_keys(Keys.ENTER)\n",
    "    print(\"End of Crawl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:08:27) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1484c60fc21e8b44054b80e719575bad7498efd5d396525e6a44287218f58e21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
